{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3_Question1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "gmg2ztQJWEFa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAVoWAwjRIVy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GpSADVyaQ95P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining model specifications\n",
        "learning_rate = 0.0003\n",
        "act_layers = [tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.softmax]\n",
        "neurons = [1024, 1024, 1024, 1024, 1024, 10]\n",
        "num_layers = len(act_layers)\n",
        "batch_size = 1000\n",
        "total_train_images = np.shape(mnist.train.images)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0iUVeCOIROKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generating a deep network of n layers with specific activation functions\n",
        "#and specified number of neurons in each layer\n",
        "def getModel(x , act_layers , neurons , u_weights , v_bar_weights , last_layer_weight):\n",
        "    num_layers = len(act_layers)\n",
        "    layers = [0]*num_layers\n",
        "    \n",
        "    if u_weights and v_bar_weights:\n",
        "      for i in range(0 , num_layers):        \n",
        "        if i == 0:\n",
        "            u_index = i // 2\n",
        "            kernel_weight = tf.constant_initializer(u_weights[u_index].eval())\n",
        "            layers[i] = tf.layers.dense(x , units= neurons[i] , activation=act_layers[i] , kernel_initializer=kernel_weight)   \n",
        "            \n",
        "        elif i < num_layers-1:\n",
        "          if i % 2 == 0:\n",
        "            u_index = i // 2\n",
        "            kernel_weight = tf.constant_initializer(u_weights[u_index].eval())\n",
        "            layers[i] = tf.layers.dense(layers[i-1] , units= neurons[i] , activation=act_layers[i] , kernel_initializer=kernel_weight)\n",
        "            \n",
        "          else:\n",
        "            v_index = i // 2\n",
        "            kernel_weight = tf.constant_initializer(v_bar_weights[v_index].eval())\n",
        "            layers[i] = tf.layers.dense(layers[i-1] , units= neurons[i] , activation=act_layers[i] , kernel_initializer=kernel_weight)\n",
        "            \n",
        "        else:\n",
        "            kernel_weight = tf.constant_initializer(last_layer_weight.eval())\n",
        "            layers[i] = tf.layers.dense(layers[i-1] , units= neurons[i] , activation=act_layers[i] , kernel_initializer=kernel_weight)\n",
        "    else:\n",
        "      for i in range(0 , num_layers):        \n",
        "          if i == 0:\n",
        "              layers[i] = tf.layers.dense(x , units= neurons[i] , activation=act_layers[i])        \n",
        "          elif i < num_layers-1:\n",
        "              layers[i] = tf.layers.dense(layers[i-1] , units= neurons[i] , activation=act_layers[i])\n",
        "          else:\n",
        "              layers[i] = tf.layers.dense(layers[i-1] , units= neurons[i] , activation=act_layers[i])\n",
        "    \n",
        "    return layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kXIu83vrRgNX",
        "colab_type": "code",
        "outputId": "852d025c-026c-4847-f0dd-5695bb09dd46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "cell_type": "code",
      "source": [
        "#Creating placeholders for input and output\n",
        "input = tf.placeholder(tf.float32, [None, 784])\n",
        "labels = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "#Getting the DNN model\n",
        "u_weights = []\n",
        "v_bar_weights = []\n",
        "last_layer_weight = []\n",
        "output = getModel(input, act_layers, neurons, u_weights , v_bar_weights , last_layer_weight)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-763c3d1456a9>:29: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dEJ8pvNsRt_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining the loss function along with its optimizer\n",
        "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = output[num_layers - 1], labels = labels)\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "correct_prediction = tf.equal(tf.argmax(output[num_layers - 1], 1), tf.argmax(labels, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qilHfBd3Fc5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training step\n",
        "Code execution will stop when 98% accuracy is achieved else when 200 epochs are computed."
      ]
    },
    {
      "metadata": {
        "id": "PwAHgRAqSvuy",
        "colab_type": "code",
        "outputId": "9e549f28-7f2f-4b56-96ef-4cbde36cfab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "cell_type": "code",
      "source": [
        "#Creating Interactivesession\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "flag = True\n",
        "count = 1\n",
        "\n",
        "#Training\n",
        "while flag:\n",
        "  #Training the model in batches of size 500\n",
        "   for i in range(total_train_images // batch_size):      \n",
        "       \n",
        "      input_batch, labels_batch = mnist.train.next_batch(batch_size)\n",
        "      feed_dict = {input: input_batch, labels: labels_batch}\n",
        "\n",
        "      train_step.run(feed_dict=feed_dict)\n",
        "      \n",
        "   #Testing\n",
        "   #Calculating the test accuracy \n",
        "   test_x , test_y = mnist.test.next_batch(10000)\n",
        "   test_accuracy = accuracy.eval(feed_dict={input: test_x, labels: test_y})\n",
        "   print(\"Epoch %d, testing accuracy %g\"%(count, test_accuracy))\n",
        "    \n",
        "  #Once training accuracy reaches 98%, training is stopped\n",
        "   if test_accuracy >= 0.98 or count >= 200:\n",
        "       flag = False\n",
        "  \n",
        "   count += 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, testing accuracy 0.9237\n",
            "Epoch 2, testing accuracy 0.9464\n",
            "Epoch 3, testing accuracy 0.959\n",
            "Epoch 4, testing accuracy 0.9645\n",
            "Epoch 5, testing accuracy 0.967\n",
            "Epoch 6, testing accuracy 0.9703\n",
            "Epoch 7, testing accuracy 0.9717\n",
            "Epoch 8, testing accuracy 0.9729\n",
            "Epoch 9, testing accuracy 0.9729\n",
            "Epoch 10, testing accuracy 0.9737\n",
            "Epoch 11, testing accuracy 0.9764\n",
            "Epoch 12, testing accuracy 0.9726\n",
            "Epoch 13, testing accuracy 0.9776\n",
            "Epoch 14, testing accuracy 0.976\n",
            "Epoch 15, testing accuracy 0.9783\n",
            "Epoch 16, testing accuracy 0.9773\n",
            "Epoch 17, testing accuracy 0.9772\n",
            "Epoch 18, testing accuracy 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kP9NRTVYGdIU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extracting variables like weights and bias from the trained model"
      ]
    },
    {
      "metadata": {
        "id": "9igYSts-l_B4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCNwuENaF8vt",
        "colab_type": "code",
        "outputId": "fef61e3a-e232-483d-ff80-14b9023d35d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "variables"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(784, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'dense/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_1/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_2/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_3/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_3/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_4/kernel:0' shape=(1024, 1024) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_4/bias:0' shape=(1024,) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_5/kernel:0' shape=(1024, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'dense_5/bias:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "y3pPzqIifDXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating separate list of all weights and bias\n",
        "W_l = []\n",
        "b_l = []\n",
        "\n",
        "for i in range(0 , len(variables) , 2):\n",
        "  W_l.append(variables[i])\n",
        "  b_l.append(variables[i+1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w1p13TTpf2vy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Computing SVD of a given matrix\n",
        "tf.svd(matrix) returns N singular values\n",
        "It is then converted into a diagonal matrix of N*N\n",
        "\"\"\"\n",
        "\n",
        "def compute_SVD(X):\n",
        "  s, u, v = tf.svd(X)\n",
        "  \n",
        "  s_diag = tf.linalg.diag(s)\n",
        "  \n",
        "  return s_diag, u, v\n",
        "\n",
        "def compute_W_bar(s, u, v):\n",
        "  v_bar = tf.matmul(s, v, adjoint_b=True)\n",
        "  result = tf.matmul(u, v_bar)\n",
        "  \n",
        "  return result , v_bar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E4gJoAJ1hlgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creating a list of:\n",
        "S - Singular values\n",
        "U - Left singular values\n",
        "V - Right singular values\n",
        "\n",
        "for all W matrix except the last one since its a small matrix\n",
        "so there is no need to compute SVD for that matrix\n",
        "\"\"\"\n",
        "s_l = []\n",
        "u_l = []\n",
        "v_l = []\n",
        "for i in range(0 , len(W_l) - 1):\n",
        "  s, u, v = compute_SVD(W_l[i])\n",
        "  \n",
        "  s_l.append(s)\n",
        "  u_l.append(u)\n",
        "  v_l.append(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jZBQxyVsd2M5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Selecting 'D' significant singular values to reduce the dimensionality\n",
        "D = [10, 20, 50, 100, 200, 'DFull']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PS_2fheyZC47",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "W_bar - Approximation of the original weight matrix. It is calculated using U.S.V\n",
        "s_d - Selecting D significant singular values\n",
        "u_d - Selecting D significant left singular values\n",
        "v_d - Selecting D significant right singular values\n",
        "v_bar = Dot product of S and V\n",
        "\"\"\"\n",
        "\n",
        "W_bar_l = []\n",
        "s_d_list = []\n",
        "u_d_list = []\n",
        "v_d_list = []\n",
        "v_bar_list = []\n",
        "\n",
        "for d_val in D:\n",
        "  for j in range(0, len(W_l) - 1):\n",
        "    if d_val == 'DFull':\n",
        "      s_d = s_l[j][: , :]\n",
        "      u_d = u_l[j][: , :]\n",
        "      v_d = v_l[j][: , :]\n",
        "    else:\n",
        "      s_d = s_l[j][:d_val , :d_val]\n",
        "      u_d = u_l[j][: , :d_val]\n",
        "      v_d = v_l[j][: , :d_val]\n",
        "        \n",
        "    s_d_list.append(s_d)\n",
        "    u_d_list.append(u_d)\n",
        "    v_d_list.append(v_d)\n",
        "    \n",
        "    result , v_bar = compute_W_bar(s_d , u_d , v_d)\n",
        "    \n",
        "    W_bar_l.append(result)\n",
        "    v_bar_list.append(v_bar)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dKpwNjN6z-TY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feedforward(input , activation_layer , weights , biases , last_layer_weight):\n",
        "  result = []\n",
        "  n = len(weights)\n",
        "  for i in range(0 , n+1):\n",
        "    if i == 0:\n",
        "      temp = activation_layer[i](tf.matmul(input , weights[i]) + biases[i])\n",
        "    elif i < n:\n",
        "      temp = activation_layer[i](tf.matmul(result[i-1] , weights[i]) + biases[i])\n",
        "    else:\n",
        "      temp = activation_layer[i](tf.matmul(result[i-1] , last_layer_weight) + biases[i])\n",
        "    \n",
        "    result.append(temp)\n",
        "   \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UQceEEdN5PBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(x , y):\n",
        "  count_equal_values = tf.equal(tf.argmax(x, 1), tf.argmax(y, 1))\n",
        "  answer = count_equal_values.eval()\n",
        "  \n",
        "  count = 0\n",
        "  for i in range(len(answer)):\n",
        "    if answer[i] == True:\n",
        "      count+=1      \n",
        "  \n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06d-gsvU7-VM",
        "colab_type": "code",
        "outputId": "b7ed1227-2f67-45d0-d37d-ee329ca81b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy_list = []\n",
        "for i in range(0 , len(W_bar_l) , 5):\n",
        "  ff_output = feedforward(test_x , act_layers , W_bar_l[i : i+5] , b_l , W_l[5])\n",
        "  accuracy = calculate_accuracy(ff_output[-1] , test_y)\n",
        "  accuracy = accuracy/test_y.shape[0]\n",
        "  \n",
        "  accuracy_list.append(accuracy)\n",
        "  print('Accuracy for D: ' + str(D[int(i/5)]) + ' is '+ str(accuracy))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for D: 10 is 0.712\n",
            "Accuracy for D: 20 is 0.8759\n",
            "Accuracy for D: 50 is 0.9449\n",
            "Accuracy for D: 100 is 0.9566\n",
            "Accuracy for D: 200 is 0.9692\n",
            "Accuracy for D: DFull is 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jkIanoUat88E",
        "colab_type": "code",
        "outputId": "49923b53-61e3-4c39-f32b-43ba69eb3551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(D , accuracy_list)\n",
        "plt.xlabel('D Singular Values')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neQmWOhERkZf4/5xSKg+43wagAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "j5hBLqWVMtMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating new model for training\n",
        "\n",
        "Since the previous model had large weight matrices, we use those trained weight matrices as a starting point for the new model. \\\\\n",
        "We replace the 5 hidden layer with 10 layers where each weight matrix(except the last one) is replaced by U and V_bar. \\\\\n",
        "Accuracy should start at a good rate because we are using the trained values in our new model."
      ]
    },
    {
      "metadata": {
        "id": "yr06u9cWNYIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining model specifications\n",
        "new_learning_rate = 0.0003\n",
        "new_act_layers = [tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.relu, tf.nn.softmax]\n",
        "new_neurons = [20, 1024, 20, 1024, 20, 1024, 20, 1024, 20, 1024, 10]\n",
        "new_num_layers = len(new_act_layers)\n",
        "new_batch_size = 1000\n",
        "total_train_images = np.shape(mnist.train.images)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bl1Np3TdMzpt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Considering D = 20 and thus only taking matrices from U_d and V_bar\n",
        "for which D = 20 and also the last layer weight\n",
        "\"\"\"\n",
        "new_output = getModel(input, new_act_layers, new_neurons , u_d_list[5 : 10] , v_bar_list[5 : 10] , W_l[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Z6aEIzRN6Mv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining the loss function along with its optimizer\n",
        "new_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = new_output[new_num_layers - 1], labels = labels)\n",
        "new_train_step = tf.train.AdamOptimizer(new_learning_rate).minimize(new_loss)\n",
        "new_correct_prediction = tf.equal(tf.argmax(new_output[new_num_layers - 1], 1), tf.argmax(labels, 1))\n",
        "new_accuracy = tf.reduce_mean(tf.cast(new_correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kFxS6cV3OHJ-",
        "colab_type": "code",
        "outputId": "17d47c91-14ae-40df-9321-914081ce81f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        }
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "flag = True\n",
        "count = 1\n",
        "\n",
        "#Training\n",
        "while flag:\n",
        "  #Training the model in batches of size 500\n",
        "   for i in range(total_train_images // new_batch_size):      \n",
        "       \n",
        "      input_batch, labels_batch = mnist.train.next_batch(new_batch_size)\n",
        "      feed_dict = {input: input_batch, labels: labels_batch}\n",
        "\n",
        "      new_train_step.run(feed_dict=feed_dict)\n",
        "      \n",
        "   #Testing\n",
        "   #Calculating the test accuracy \n",
        "   test_x , test_y = mnist.test.next_batch(10000)\n",
        "   new_test_accuracy = new_accuracy.eval(feed_dict={input: test_x, labels: test_y})\n",
        "   print(\"Epoch %d, testing accuracy %g\"%(count, new_test_accuracy))\n",
        "    \n",
        "  #Once training accuracy reaches 98%, training is stopped\n",
        "   if new_test_accuracy >= 0.97 or count >= 200:\n",
        "       flag = False\n",
        "  \n",
        "   count += 1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, testing accuracy 0.695\n",
            "Epoch 2, testing accuracy 0.7983\n",
            "Epoch 3, testing accuracy 0.8487\n",
            "Epoch 4, testing accuracy 0.8566\n",
            "Epoch 5, testing accuracy 0.861\n",
            "Epoch 6, testing accuracy 0.8664\n",
            "Epoch 7, testing accuracy 0.8663\n",
            "Epoch 8, testing accuracy 0.8699\n",
            "Epoch 9, testing accuracy 0.8686\n",
            "Epoch 10, testing accuracy 0.8728\n",
            "Epoch 11, testing accuracy 0.8723\n",
            "Epoch 12, testing accuracy 0.9383\n",
            "Epoch 13, testing accuracy 0.9531\n",
            "Epoch 14, testing accuracy 0.9566\n",
            "Epoch 15, testing accuracy 0.9556\n",
            "Epoch 16, testing accuracy 0.9623\n",
            "Epoch 17, testing accuracy 0.9621\n",
            "Epoch 18, testing accuracy 0.9624\n",
            "Epoch 19, testing accuracy 0.9619\n",
            "Epoch 20, testing accuracy 0.9624\n",
            "Epoch 21, testing accuracy 0.9641\n",
            "Epoch 22, testing accuracy 0.9664\n",
            "Epoch 23, testing accuracy 0.9629\n",
            "Epoch 24, testing accuracy 0.9621\n",
            "Epoch 25, testing accuracy 0.9635\n",
            "Epoch 26, testing accuracy 0.9671\n",
            "Epoch 27, testing accuracy 0.9652\n",
            "Epoch 28, testing accuracy 0.9654\n",
            "Epoch 29, testing accuracy 0.9643\n",
            "Epoch 30, testing accuracy 0.9645\n",
            "Epoch 31, testing accuracy 0.963\n",
            "Epoch 32, testing accuracy 0.9628\n",
            "Epoch 33, testing accuracy 0.9662\n",
            "Epoch 34, testing accuracy 0.9671\n",
            "Epoch 35, testing accuracy 0.9622\n",
            "Epoch 36, testing accuracy 0.9648\n",
            "Epoch 37, testing accuracy 0.9673\n",
            "Epoch 38, testing accuracy 0.9665\n",
            "Epoch 39, testing accuracy 0.9671\n",
            "Epoch 40, testing accuracy 0.9674\n",
            "Epoch 41, testing accuracy 0.9686\n",
            "Epoch 42, testing accuracy 0.9663\n",
            "Epoch 43, testing accuracy 0.9665\n",
            "Epoch 44, testing accuracy 0.9687\n",
            "Epoch 45, testing accuracy 0.9672\n",
            "Epoch 46, testing accuracy 0.9692\n",
            "Epoch 47, testing accuracy 0.9666\n",
            "Epoch 48, testing accuracy 0.9702\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}